{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "447b99dd-259c-4636-ae33-6e5be8b51249",
      "metadata": {},
      "source": [
        "## Distillation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1230f185-edf0-4c37-a1bd-2fc594aa2b87",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Lade Daten: 100%|██████████████████████████████████████████████████████████████| 26482/26482 [00:17<00:00, 1473.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Student-Datensatz: 126219 Sequenzen á 100 Frames\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Berechne Teacher-Logits: 100%|███████████████████████████████████████████████| 126219/126219 [1:31:30<00:00, 22.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧪 Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|███████████████████████████████████████████| 1973/1973 [01:34<00:00, 20.91batch/s, loss=0.88, acc=0.604]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6042\n",
            "\n",
            "🧪 Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:32<00:00, 21.25batch/s, loss=0.908, acc=0.656]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6557\n",
            "\n",
            "🧪 Epoch 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|███████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.18batch/s, loss=0.707, acc=0.67]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6696\n",
            "\n",
            "🧪 Epoch 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.18batch/s, loss=0.633, acc=0.678]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6778\n",
            "\n",
            "🧪 Epoch 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.16batch/s, loss=0.706, acc=0.684]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6836\n",
            "\n",
            "🧪 Epoch 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.06batch/s, loss=0.601, acc=0.688]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6877\n",
            "\n",
            "🧪 Epoch 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.16batch/s, loss=0.626, acc=0.691]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6908\n",
            "\n",
            "🧪 Epoch 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.15batch/s, loss=0.581, acc=0.694]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6938\n",
            "\n",
            "🧪 Epoch 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:32<00:00, 21.23batch/s, loss=0.735, acc=0.696]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6958\n",
            "\n",
            "🧪 Epoch 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|███████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.17batch/s, loss=0.77, acc=0.698]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6978\n",
            "\n",
            "🧪 Epoch 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.13batch/s, loss=0.488, acc=0.699]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.6994\n",
            "\n",
            "🧪 Epoch 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.10batch/s, loss=0.502, acc=0.701]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.7010\n",
            "\n",
            "🧪 Epoch 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.16batch/s, loss=0.576, acc=0.702]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.7023\n",
            "\n",
            "🧪 Epoch 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.13batch/s, loss=0.454, acc=0.703]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.7035\n",
            "\n",
            "🧪 Epoch 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.13batch/s, loss=0.507, acc=0.705]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.7048\n",
            "\n",
            "🧪 Epoch 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.09batch/s, loss=0.547, acc=0.706]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.7057\n",
            "\n",
            "🧪 Epoch 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|███████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.18batch/s, loss=0.61, acc=0.706]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.7063\n",
            "\n",
            "🧪 Epoch 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.16batch/s, loss=0.447, acc=0.707]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.7073\n",
            "\n",
            "🧪 Epoch 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.15batch/s, loss=0.556, acc=0.708]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.7081\n",
            "\n",
            "🧪 Epoch 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████████████████████████████████████| 1973/1973 [01:33<00:00, 21.17batch/s, loss=0.754, acc=0.709]\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Epoch Accuracy: 0.7089\n",
            "✅ Student-Modell gespeichert als student_model_distilled.h5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Parameter ===\n",
        "FEATURE_DIR = \"data/en/features_clean\"\n",
        "LABEL_DIR = \"data/en/labels_clean\"\n",
        "segment_len = 100\n",
        "input_dim = 39\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "TEMPERATURE = 5.0\n",
        "ALPHA = 0.5\n",
        "\n",
        "# === Teacher Modell laden ===\n",
        "teacher_model = load_model(\"teacher_phoneme_model.h5\")\n",
        "teacher_model.trainable = False\n",
        "\n",
        "# === Feature-Normalisierung laden ===\n",
        "mean = np.load(\"feature_mean.npy\")\n",
        "std = np.load(\"feature_std.npy\")\n",
        "\n",
        "# === Label-Encoder vorbereiten ===\n",
        "all_labels = []\n",
        "for file in os.listdir(LABEL_DIR):\n",
        "    with open(os.path.join(LABEL_DIR, file)) as f:\n",
        "        all_labels.extend([line.strip() for line in f])\n",
        "distinct_phonemes = sorted(set(all_labels))\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(distinct_phonemes)\n",
        "\n",
        "# === Sequenzaufteilung ===\n",
        "def split_sequence(X, y, segment_len):\n",
        "    segments_X, segments_y = [], []\n",
        "    max_start = (len(X) // segment_len) * segment_len\n",
        "    for start in range(0, max_start, segment_len):\n",
        "        segments_X.append(X[start:start + segment_len])\n",
        "        segments_y.append(y[start:start + segment_len])\n",
        "    return segments_X, segments_y\n",
        "\n",
        "# === Daten laden ===\n",
        "X_all, y_all = [], []\n",
        "for file in tqdm(os.listdir(FEATURE_DIR), desc=\"Lade Daten\"):\n",
        "    if not file.endswith(\".npy\"):\n",
        "        continue\n",
        "    base = os.path.splitext(file)[0]\n",
        "    features = np.load(os.path.join(FEATURE_DIR, file))\n",
        "    features = (features - mean) / std\n",
        "    with open(os.path.join(LABEL_DIR, f\"{base}.txt\")) as f:\n",
        "        labels = [line.strip() for line in f]\n",
        "    if len(features) != len(labels):\n",
        "        continue\n",
        "    labels_encoded = label_encoder.transform(labels)\n",
        "    X_seg, y_seg = split_sequence(features, labels_encoded, segment_len)\n",
        "    X_all.extend(X_seg)\n",
        "    y_all.extend(y_seg)\n",
        "\n",
        "X_all = np.array(X_all)\n",
        "y_all = np.array(y_all)\n",
        "print(f\"✅ Student-Datensatz: {X_all.shape[0]} Sequenzen á {segment_len} Frames\")\n",
        "\n",
        "# === Teacher-Logits vorberechnen (Distillation Targets) ===\n",
        "TEACHER_LOGITS_PATH = \"teacher_logits.npy\"\n",
        "if not os.path.exists(TEACHER_LOGITS_PATH):\n",
        "    teacher_logits = []\n",
        "    for x in tqdm(X_all, desc=\"Berechne Teacher-Logits\"):\n",
        "        pred = teacher_model.predict(np.expand_dims(x, axis=0), verbose=0)\n",
        "        teacher_logits.append(pred.squeeze() / TEMPERATURE)\n",
        "    teacher_logits = np.array(teacher_logits)\n",
        "    np.save(TEACHER_LOGITS_PATH, teacher_logits)\n",
        "else:\n",
        "    teacher_logits = np.load(TEACHER_LOGITS_PATH)\n",
        "\n",
        "# === tf.data.Dataset ===\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_all, y_all, teacher_logits))\n",
        "dataset = dataset.shuffle(2048).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# === Kompaktes Student-Modell ===\n",
        "inputs = Input(shape=(segment_len, input_dim))\n",
        "x = layers.Conv1D(64, 3, padding='same', activation='relu')(inputs)\n",
        "x = layers.Bidirectional(layers.GRU(64, return_sequences=True))(x)\n",
        "outputs = layers.TimeDistributed(layers.Dense(len(distinct_phonemes), activation='softmax'))(x)\n",
        "student_model = models.Model(inputs, outputs)\n",
        "\n",
        "# === Distillation Loss ===\n",
        "def distillation_loss(y_true, y_pred, teacher_soft):\n",
        "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=len(distinct_phonemes))\n",
        "    y_pred_soft = tf.nn.softmax(y_pred / TEMPERATURE)\n",
        "    loss_true = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "    loss_soft = tf.keras.losses.KLD(teacher_soft, y_pred_soft)\n",
        "    return ALPHA * loss_soft + (1 - ALPHA) * loss_true\n",
        "\n",
        "# === Training Setup ===\n",
        "optimizer = Adam(1e-3)\n",
        "train_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y, t_soft):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = student_model(x, training=True)\n",
        "        loss = tf.reduce_mean(distillation_loss(y, pred, t_soft))\n",
        "    grads = tape.gradient(loss, student_model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, student_model.trainable_variables))\n",
        "    train_acc.update_state(y, pred)\n",
        "    return loss\n",
        "\n",
        "# === Training Loop ===\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\n🧪 Epoch {epoch + 1}/{EPOCHS}\")\n",
        "    pbar = tqdm(dataset, desc=\"Training\", unit=\"batch\")\n",
        "    for batch_x, batch_y, batch_teacher_soft in pbar:\n",
        "        loss = train_step(batch_x, batch_y, batch_teacher_soft)\n",
        "        pbar.set_postfix({\"loss\": loss.numpy(), \"acc\": train_acc.result().numpy()})\n",
        "    print(f\"🔍 Epoch Accuracy: {train_acc.result().numpy():.4f}\")\n",
        "    train_acc.reset_state()\n",
        "\n",
        "# === Speichern ===\n",
        "student_model.save(\"student_model_distilled.h5\")\n",
        "print(\"✅ Student-Modell gespeichert als student_model_distilled.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
