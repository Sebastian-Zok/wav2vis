{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fa9fa6-2a5f-4eff-8c2f-070e11e7c696",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Make sure to use the correct data. The .phn files should be in the TIMIT format and the audios as wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9725ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from multiprocessing import cpu_count\n",
    "import logging\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FeatureExtractor:\n",
    "    \"\"\"Improved Feature Extractor with better error handling and normalization\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        # Default configuration\n",
    "        self.sr = 16000\n",
    "        self.n_fft = 400         # 25 ms\n",
    "        self.hop_length = 160    # 10 ms  \n",
    "        self.n_mfcc = 13\n",
    "        self.include_delta = True\n",
    "        self.include_delta2 = True\n",
    "        \n",
    "        # Updated paths to match actual structure\n",
    "        self.base_dir = Path(\"datasets_original/en\")\n",
    "        self.wav_dir = self.base_dir / \"wav\"\n",
    "        self.phn_dir = self.base_dir / \"phn\"\n",
    "        self.features_out = self.base_dir / \"features\"\n",
    "        self.labels_out = self.base_dir / \"labels\"\n",
    "        \n",
    "        # Create output directories\n",
    "        self.features_out.mkdir(parents=True, exist_ok=True)\n",
    "        self.labels_out.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Statistics for global normalization\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        # Error tracking\n",
    "        self.errors = []\n",
    "        self.processed_files = []\n",
    "        \n",
    "    def validate_paths(self):\n",
    "        \"\"\"Validate that required directories exist\"\"\"\n",
    "        if not self.wav_dir.exists():\n",
    "            raise FileNotFoundError(f\"WAV directory not found: {self.wav_dir}\")\n",
    "        if not self.phn_dir.exists():\n",
    "            raise FileNotFoundError(f\"PHN directory not found: {self.phn_dir}\")\n",
    "            \n",
    "        wav_files = list(self.wav_dir.glob(\"*.wav\"))\n",
    "        phn_files = list(self.phn_dir.glob(\"*.phn\"))\n",
    "        \n",
    "        logger.info(f\"Found {len(wav_files)} WAV files and {len(phn_files)} PHN files\")\n",
    "        return len(wav_files), len(phn_files)\n",
    "    \n",
    "    def load_phoneme_intervals(self, phn_path):\n",
    "        \"\"\"Load phoneme intervals from PHN file with validation\"\"\"\n",
    "        intervals = []\n",
    "        try:\n",
    "            with open(phn_path, \"r\", encoding='utf-8') as f:\n",
    "                for line_num, line in enumerate(f, 1):\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                        \n",
    "                    parts = line.split()\n",
    "                    if len(parts) != 3:\n",
    "                        logger.warning(f\"Invalid line {line_num} in {phn_path}: {line}\")\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        start_samples, end_samples, phoneme = parts\n",
    "                        start_time = int(start_samples) / self.sr\n",
    "                        end_time = int(end_samples) / self.sr\n",
    "                        \n",
    "                        # Validation\n",
    "                        if start_time >= end_time:\n",
    "                            logger.warning(f\"Invalid time interval in {phn_path}: {start_time} >= {end_time}\")\n",
    "                            continue\n",
    "                            \n",
    "                        intervals.append((start_time, end_time, phoneme.upper()))\n",
    "                    except ValueError as e:\n",
    "                        logger.warning(f\"Could not parse line {line_num} in {phn_path}: {e}\")\n",
    "                        continue\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {phn_path}: {e}\")\n",
    "            return []\n",
    "        \n",
    "        return intervals\n",
    "    \n",
    "    def assign_labels_robust(self, num_frames, frame_times, intervals):\n",
    "        \"\"\"Robust label assignment with overlap handling\"\"\"\n",
    "        labels = [\"SIL\"] * num_frames\n",
    "        \n",
    "        for i, frame_time in enumerate(frame_times):\n",
    "            assigned = False\n",
    "            for start_time, end_time, phoneme in intervals:\n",
    "                # Use frame center for assignment\n",
    "                if start_time <= frame_time < end_time:\n",
    "                    labels[i] = phoneme\n",
    "                    assigned = True\n",
    "                    break\n",
    "            \n",
    "            # If not assigned and we have intervals, find closest\n",
    "            if not assigned and intervals:\n",
    "                closest_interval = min(intervals, \n",
    "                                     key=lambda x: min(abs(frame_time - x[0]), abs(frame_time - x[1])))\n",
    "                # Only assign if reasonably close (within 50ms)\n",
    "                if min(abs(frame_time - closest_interval[0]), abs(frame_time - closest_interval[1])) < 0.05:\n",
    "                    labels[i] = closest_interval[2]\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def extract_features_single(self, wav_path, normalize=False):\n",
    "        \"\"\"Extract features from a single audio file\"\"\"\n",
    "        try:\n",
    "            # Load audio with validation\n",
    "            y, sr_actual = librosa.load(wav_path, sr=self.sr)\n",
    "            \n",
    "            if len(y) == 0:\n",
    "                raise ValueError(\"Empty audio file\")\n",
    "            \n",
    "            if sr_actual != self.sr:\n",
    "                logger.warning(f\"Sample rate mismatch in {wav_path}: {sr_actual} vs {self.sr}\")\n",
    "            \n",
    "            # Extract MFCC features\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=y, sr=self.sr, n_mfcc=self.n_mfcc, \n",
    "                n_fft=self.n_fft, hop_length=self.hop_length\n",
    "            )\n",
    "            \n",
    "            features = [mfcc]\n",
    "            \n",
    "            # Add delta features if requested\n",
    "            if self.include_delta:\n",
    "                delta = librosa.feature.delta(mfcc)\n",
    "                features.append(delta)\n",
    "                \n",
    "            if self.include_delta2:\n",
    "                delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "                features.append(delta2)\n",
    "            \n",
    "            # Combine features [n_features, n_frames] -> [n_frames, n_features]\n",
    "            combined_features = np.vstack(features).T\n",
    "            \n",
    "            # Local normalization if global not available yet\n",
    "            if normalize and not self.is_fitted:\n",
    "                mean = np.mean(combined_features, axis=0)\n",
    "                std = np.std(combined_features, axis=0) + 1e-8\n",
    "                combined_features = (combined_features - mean) / std\n",
    "            \n",
    "            return combined_features, y\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Feature extraction failed for {wav_path}: {e}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f350053f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Methods successfully updated to handle WAV-PHN file matching!\n"
     ]
    }
   ],
   "source": [
    "def process_file_robust(self, base_name):\n",
    "    \"\"\"Process a single file with comprehensive error handling\"\"\"\n",
    "    wav_path = self.wav_dir / f\"{base_name}.wav\"\n",
    "    phn_path = self.phn_dir / f\"{base_name}.phn\"\n",
    "    \n",
    "    # Check if files exist\n",
    "    if not wav_path.exists():\n",
    "        error_msg = f\"WAV file missing: {wav_path}\"\n",
    "        self.errors.append(error_msg)\n",
    "        return {\"status\": \"missing_wav\", \"base\": base_name, \"error\": error_msg}\n",
    "        \n",
    "    if not phn_path.exists():\n",
    "        error_msg = f\"PHN file missing: {phn_path}\"\n",
    "        self.errors.append(error_msg)\n",
    "        return {\"status\": \"missing_phn\", \"base\": base_name, \"error\": error_msg}\n",
    "    \n",
    "    try:\n",
    "        # Extract features\n",
    "        features, audio = self.extract_features_single(wav_path, normalize=True)\n",
    "        if features is None:\n",
    "            return {\"status\": \"feature_error\", \"base\": base_name}\n",
    "        \n",
    "        # Load phoneme intervals\n",
    "        intervals = self.load_phoneme_intervals(phn_path)\n",
    "        if not intervals:\n",
    "            error_msg = f\"No valid phoneme intervals found in {phn_path}\"\n",
    "            self.errors.append(error_msg)\n",
    "            return {\"status\": \"no_intervals\", \"base\": base_name, \"error\": error_msg}\n",
    "        \n",
    "        # Calculate frame times\n",
    "        num_frames = features.shape[0]\n",
    "        frame_times = (np.arange(num_frames) * self.hop_length + self.n_fft // 2) / self.sr\n",
    "        \n",
    "        # Assign labels\n",
    "        labels = self.assign_labels_robust(num_frames, frame_times, intervals)\n",
    "        \n",
    "        # Validation: check if we have reasonable label distribution\n",
    "        unique_labels = set(labels)\n",
    "        if len(unique_labels) <= 1:\n",
    "            error_msg = f\"Only one unique label found: {unique_labels}\"\n",
    "            self.errors.append(error_msg)\n",
    "            return {\"status\": \"label_error\", \"base\": base_name, \"error\": error_msg}\n",
    "        \n",
    "        # Save features and labels\n",
    "        feature_file = self.features_out / f\"{base_name}.npy\"\n",
    "        label_file = self.labels_out / f\"{base_name}.txt\"\n",
    "        \n",
    "        np.save(feature_file, features.astype(np.float32))\n",
    "        with open(label_file, \"w\", encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(labels))\n",
    "        \n",
    "        # Return statistics\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"base\": base_name,\n",
    "            \"frames\": num_frames,\n",
    "            \"duration\": len(audio) / self.sr,\n",
    "            \"unique_labels\": len(unique_labels),\n",
    "            \"label_distribution\": {label: labels.count(label) for label in unique_labels}\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Processing error for {base_name}: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        self.errors.append(error_msg)\n",
    "        return {\"status\": \"processing_error\", \"base\": base_name, \"error\": error_msg}\n",
    "\n",
    "def collect_statistics_pass(self, file_list, max_files=None):\n",
    "    \"\"\"First pass: collect statistics for global normalization\"\"\"\n",
    "    logger.info(\"Collecting statistics for global normalization...\")\n",
    "    \n",
    "    if max_files:\n",
    "        file_list = file_list[:max_files]\n",
    "    \n",
    "    all_features = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=min(cpu_count(), 8)) as executor:\n",
    "        futures = []\n",
    "        for base_name in file_list:\n",
    "            wav_path = self.wav_dir / f\"{base_name}.wav\"\n",
    "            phn_path = self.phn_dir / f\"{base_name}.phn\"\n",
    "            # Only process if both files exist\n",
    "            if wav_path.exists() and phn_path.exists():\n",
    "                future = executor.submit(self.extract_features_single, wav_path, normalize=False)\n",
    "                futures.append(future)\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Collecting stats\"):\n",
    "            try:\n",
    "                features, _ = future.result()\n",
    "                if features is not None:\n",
    "                    # Sample frames if too many (for memory efficiency)\n",
    "                    if features.shape[0] > 1000:\n",
    "                        indices = np.random.choice(features.shape[0], 1000, replace=False)\n",
    "                        features = features[indices]\n",
    "                    all_features.append(features)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error in statistics collection: {e}\")\n",
    "    \n",
    "    if all_features:\n",
    "        # Combine all features for global statistics\n",
    "        combined = np.vstack(all_features)\n",
    "        self.scaler.fit(combined)\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        # Save scaler for later use\n",
    "        scaler_path = self.base_dir / \"feature_scaler.pkl\"\n",
    "        with open(scaler_path, 'wb') as f:\n",
    "            pickle.dump(self.scaler, f)\n",
    "        \n",
    "        logger.info(f\"Global normalization fitted on {combined.shape[0]} frames\")\n",
    "        logger.info(f\"Feature dimensions: {combined.shape[1]}\")\n",
    "        logger.info(f\"Scaler saved to: {scaler_path}\")\n",
    "    else:\n",
    "        logger.error(\"No features collected for normalization!\")\n",
    "\n",
    "def process_all_files(self, max_workers=None, collect_stats=True, max_stats_files=1000):\n",
    "    \"\"\"Process all files with improved pipeline - only files with both WAV and PHN\"\"\"\n",
    "    try:\n",
    "        # Validate paths first\n",
    "        self.validate_paths()\n",
    "        \n",
    "        # Get all base names that have both WAV and PHN files\n",
    "        wav_files = list(self.wav_dir.glob(\"*.wav\"))\n",
    "        phn_files = list(self.phn_dir.glob(\"*.phn\"))\n",
    "        \n",
    "        wav_bases = {f.stem for f in wav_files}\n",
    "        phn_bases = {f.stem for f in phn_files}\n",
    "        \n",
    "        # Only process files that have both WAV and PHN\n",
    "        matching_bases = wav_bases & phn_bases\n",
    "        missing_phn = wav_bases - phn_bases\n",
    "        \n",
    "        if not matching_bases:\n",
    "            logger.error(\"No files found that have both WAV and PHN!\")\n",
    "            return\n",
    "        \n",
    "        logger.info(f\"Found {len(wav_files)} WAV files and {len(phn_files)} PHN files\")\n",
    "        logger.info(f\"Processing {len(matching_bases)} files that have both WAV and PHN\")\n",
    "        if missing_phn:\n",
    "            logger.info(f\"Skipping {len(missing_phn)} WAV files without corresponding PHN files\")\n",
    "        \n",
    "        base_names = list(matching_bases)\n",
    "        \n",
    "        # First pass: collect statistics for normalization\n",
    "        if collect_stats:\n",
    "            self.collect_statistics_pass(base_names, max_stats_files)\n",
    "        \n",
    "        # Second pass: process all files with global normalization\n",
    "        logger.info(\"Processing all matching files...\")\n",
    "        \n",
    "        if max_workers is None:\n",
    "            max_workers = min(cpu_count(), 8)\n",
    "        \n",
    "        results = []\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {executor.submit(self.process_file_robust, base): base for base in base_names}\n",
    "            \n",
    "            for future in tqdm(as_completed(futures), total=len(futures), \n",
    "                                desc=\"Processing files\", unit=\"files\"):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "                except Exception as e:\n",
    "                    base = futures[future]\n",
    "                    error_msg = f\"Unexpected error processing {base}: {e}\"\n",
    "                    logger.error(error_msg)\n",
    "                    self.errors.append(error_msg)\n",
    "                    results.append({\"status\": \"unexpected_error\", \"base\": base, \"error\": error_msg})\n",
    "        \n",
    "        # Process results\n",
    "        self.analyze_results(results)\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error in processing pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "def analyze_results(self, results):\n",
    "    \"\"\"Analyze and report processing results\"\"\"\n",
    "    status_counts = {}\n",
    "    successful_files = []\n",
    "    \n",
    "    for result in results:\n",
    "        status = result[\"status\"]\n",
    "        status_counts[status] = status_counts.get(status, 0) + 1\n",
    "        if status == \"success\":\n",
    "            successful_files.append(result)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FEATURE EXTRACTION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total files processed: {len(results)}\")\n",
    "    \n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"{status:.<20} {count:>6}\")\n",
    "    \n",
    "    if successful_files:\n",
    "        # Statistics on successful files\n",
    "        total_frames = sum(r[\"frames\"] for r in successful_files)\n",
    "        total_duration = sum(r[\"duration\"] for r in successful_files)\n",
    "        avg_duration = total_duration / len(successful_files)\n",
    "        \n",
    "        print(f\"\\nSuccessful processing statistics:\")\n",
    "        print(f\"Total frames: {total_frames:,}\")\n",
    "        print(f\"Total duration: {total_duration:.2f} seconds ({total_duration/3600:.2f} hours)\")\n",
    "        print(f\"Average duration: {avg_duration:.2f} seconds\")\n",
    "    \n",
    "    # Save error log\n",
    "    if self.errors:\n",
    "        error_log_path = self.base_dir / \"feature_extraction_errors.log\"\n",
    "        with open(error_log_path, \"w\", encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(self.errors))\n",
    "        print(f\"\\nErrors logged to: {error_log_path}\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Dynamically add the methods to the FeatureExtractor class\n",
    "FeatureExtractor.process_file_robust = process_file_robust\n",
    "FeatureExtractor.collect_statistics_pass = collect_statistics_pass  \n",
    "FeatureExtractor.process_all_files = process_all_files\n",
    "FeatureExtractor.analyze_results = analyze_results\n",
    "\n",
    "print(\"✅ Methods successfully updated to handle WAV-PHN file matching!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26b293a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\src\\data_processing\n",
      "Project root: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\n",
      "Looking for data in: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\n",
      "✅ Data directory found: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\n",
      "WAV dir exists: True\n",
      "PHN dir exists: True\n",
      "✅ Extractor configured with:\n",
      "  Base dir: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\n",
      "  WAV dir: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\\wav\n",
      "  PHN dir: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\\phn\n",
      "  Features out: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\\features\n",
      "  Labels out: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\\labels\n",
      "\n",
      "📊 Existing Data Analysis:\n",
      "Existing feature files: 26482\n",
      "Existing label files: 26482\n",
      "✅ Found existing features and labels - ready for OOV cleaning!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the improved feature extractor with correct paths\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the correct base directory\n",
    "notebook_dir = Path.cwd()\n",
    "print(f\"Current directory: {notebook_dir}\")\n",
    "\n",
    "# Navigate to project root\n",
    "if \"src\" in notebook_dir.parts:\n",
    "    # We're in src/data_processing, go up to project root\n",
    "    project_root = notebook_dir.parent.parent\n",
    "elif notebook_dir.name == \"notebooks\":\n",
    "    project_root = notebook_dir.parent\n",
    "else:\n",
    "    project_root = notebook_dir\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Looking for data in: {project_root / 'datasets_original' / 'en'}\")\n",
    "\n",
    "# Check if the path exists\n",
    "data_path = project_root / \"datasets_original\" / \"en\"\n",
    "if data_path.exists():\n",
    "    print(f\"✅ Data directory found: {data_path}\")\n",
    "    wav_path = data_path / \"wav\"\n",
    "    phn_path = data_path / \"phn\"\n",
    "    print(f\"WAV dir exists: {wav_path.exists()}\")\n",
    "    print(f\"PHN dir exists: {phn_path.exists()}\")\n",
    "    \n",
    "    if wav_path.exists() and phn_path.exists():\n",
    "        # Initialize extractor with correct base directory\n",
    "        extractor = FeatureExtractor()\n",
    "        extractor.base_dir = data_path\n",
    "        extractor.wav_dir = data_path / \"wav\"\n",
    "        extractor.phn_dir = data_path / \"phn\"\n",
    "        extractor.features_out = data_path / \"features\"\n",
    "        extractor.labels_out = data_path / \"labels\"\n",
    "        \n",
    "        # Create output directories\n",
    "        extractor.features_out.mkdir(parents=True, exist_ok=True)\n",
    "        extractor.labels_out.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"✅ Extractor configured with:\")\n",
    "        print(f\"  Base dir: {extractor.base_dir}\")\n",
    "        print(f\"  WAV dir: {extractor.wav_dir}\")\n",
    "        print(f\"  PHN dir: {extractor.phn_dir}\")\n",
    "        print(f\"  Features out: {extractor.features_out}\")\n",
    "        print(f\"  Labels out: {extractor.labels_out}\")\n",
    "        \n",
    "        # Check if features and labels already exist\n",
    "        feature_files = list(extractor.features_out.glob(\"*.npy\"))\n",
    "        label_files = list(extractor.labels_out.glob(\"*.txt\"))\n",
    "        \n",
    "        print(f\"\\n📊 Existing Data Analysis:\")\n",
    "        print(f\"Existing feature files: {len(feature_files)}\")\n",
    "        print(f\"Existing label files: {len(label_files)}\")\n",
    "        \n",
    "        if feature_files and label_files:\n",
    "            print(\"✅ Found existing features and labels - ready for OOV cleaning!\")\n",
    "        else:\n",
    "            print(\"⚠️ No existing features/labels found - run feature extraction first!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ WAV or PHN directories not found!\")\n",
    "        print(f\"Available in {data_path}:\")\n",
    "        if data_path.exists():\n",
    "            for item in data_path.iterdir():\n",
    "                if item.is_dir():\n",
    "                    print(f\"  {item.name}\")\n",
    "else:\n",
    "    print(f\"❌ Data directory not found: {data_path}\")\n",
    "    print(\"Available directories in project root:\")\n",
    "    if project_root.exists():\n",
    "        for item in project_root.iterdir():\n",
    "            if item.is_dir():\n",
    "                print(f\"  {item.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d37417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING FULL FEATURE EXTRACTION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Found 676641 WAV files and 26482 PHN files\n",
      "INFO:__main__:Found 676641 WAV files and 26482 PHN files\n",
      "INFO:__main__:Processing 26482 files that have both WAV and PHN\n",
      "INFO:__main__:Skipping 650159 WAV files without corresponding PHN files\n",
      "INFO:__main__:Collecting statistics for global normalization...\n",
      "INFO:__main__:Found 676641 WAV files and 26482 PHN files\n",
      "INFO:__main__:Processing 26482 files that have both WAV and PHN\n",
      "INFO:__main__:Skipping 650159 WAV files without corresponding PHN files\n",
      "INFO:__main__:Collecting statistics for global normalization...\n",
      "Collecting stats: 100%|██████████| 1000/1000 [00:02<00:00, 403.41it/s]\n",
      "\n",
      "INFO:__main__:Global normalization fitted on 523595 frames\n",
      "INFO:__main__:Feature dimensions: 39\n",
      "INFO:__main__:Scaler saved to: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\\feature_scaler.pkl\n",
      "INFO:__main__:Global normalization fitted on 523595 frames\n",
      "INFO:__main__:Feature dimensions: 39\n",
      "INFO:__main__:Scaler saved to: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\\feature_scaler.pkl\n",
      "INFO:__main__:Processing all matching files...\n",
      "INFO:__main__:Processing all matching files...\n",
      "Processing files: 100%|██████████| 26482/26482 [02:35<00:00, 170.58files/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FEATURE EXTRACTION RESULTS\n",
      "==================================================\n",
      "Total files processed: 26482\n",
      "success.............  26482\n",
      "\n",
      "Successful processing statistics:\n",
      "Total frames: 14,237,225\n",
      "Total duration: 142221.29 seconds (39.51 hours)\n",
      "Average duration: 5.37 seconds\n",
      "==================================================\n",
      "\n",
      "✅ Feature extraction completed successfully!\n",
      "📄 Processing report saved to: c:\\Users\\sebas\\Desktop\\commonVoiceDataset\\datasets_original\\en\\processing_report.txt\n"
     ]
    }
   ],
   "source": [
    "# Full processing with the improved pipeline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING FULL FEATURE EXTRACTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Process all files\n",
    "    results = extractor.process_all_files(\n",
    "        max_workers=cpu_count(),  # Use all available cores\n",
    "        collect_stats=True,       # Collect statistics for global normalization\n",
    "        max_stats_files=1000      # Use subset for statistics (memory efficiency)\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Feature extraction completed successfully!\")\n",
    "    \n",
    "    # Optional: Save processing report\n",
    "    if results:\n",
    "        report_path = extractor.base_dir / \"processing_report.txt\"\n",
    "        with open(report_path, \"w\", encoding='utf-8') as f:\n",
    "            f.write(\"Feature Extraction Report\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\\n\")\n",
    "            \n",
    "            status_counts = {}\n",
    "            for result in results:\n",
    "                status = result[\"status\"]\n",
    "                status_counts[status] = status_counts.get(status, 0) + 1\n",
    "            \n",
    "            for status, count in status_counts.items():\n",
    "                f.write(f\"{status}: {count}\\n\")\n",
    "        \n",
    "        print(f\"📄 Processing report saved to: {report_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Feature extraction failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54eef684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "VALIDATING EXTRACTED DATA\n",
      "==================================================\n",
      "Feature files: 26482\n",
      "Label files: 26482\n",
      "Matching pairs: 26482\n",
      "\n",
      "Validating 20 sample files...\n",
      "✅ 449dc4bdcb0b674ce1a0a868a1c46a4b959625fe76065922d7329e44673e727e1051c7e09e6fe923487bdbb8f8a4726845c69fb038026083e26469c8f5502c24: 697 frames, 24 unique phonemes\n",
      "✅ 7edb2af1e2f4fc20864cd7ca641c5f43a77b96dc50ae9091417b39e237bf1936e1ae7a28d52dc5fb591108b9921c15c63896914fe6f6b89021ff10aba540888e: 346 frames, 12 unique phonemes\n",
      "✅ 8b6f2401d6c5d31d3afa804c37559dce47696cb31735bdd213a3c6567b44c38bdd14b303110a950c71c4cd33d75da0ca43aca8efdb9dedd44ee848e6aa7f8ea6: 310 frames, 13 unique phonemes\n",
      "✅ d6c3894252d0c62099fffaefb680eee43f84cd181a88ec4e219daf2da8e3b4becea0db68f946a9592434d01efe5a2a22890f86ae6fe2728a739dd718ab0dd9a1: 989 frames, 16 unique phonemes\n",
      "✅ a721196a35faa57cae99a3cd0260647d5b64beef00f6d83a2ce38d5c2f8b987faca1043b04e1e3671f43a93a396a8503fdaf5eb9808a960f63524b4ad1088bdc: 274 frames, 12 unique phonemes\n",
      "✅ 39bd19fcce3ff45adf9cf8e6168117f0b0cdba49df6ad802ea0cf80925aba17b193d9dd5627ce676c0c55e05e868c7aac57edb9b788df55db3686680dc96237c: 637 frames, 14 unique phonemes\n",
      "✅ e57df6a9e6756821673bc44742901c456aae90ac7b3e0e6eb94e0611eefa43db9057e14dc960c7ec3a6020b573c9d3ff93be5cb023a912abe9a325b55601a12d: 421 frames, 21 unique phonemes\n",
      "✅ 2f6f2a60f942887092bb3c155d90bdee52ed4927b448f7970a68f3ae87d3206d1ebad14142adc249c198fa2658900263596ff992abe648d0dd8c613178b7bb37: 478 frames, 17 unique phonemes\n",
      "✅ 7b3dd6aa7e1e677c4fc34a7f3723ff6ccc9acb4209b094acd0cfacbc4f85b3e2052f4f9b61cc35909a097d2a0b5a62df1a55861dc0899610645dcaf27e66610e: 476 frames, 18 unique phonemes\n",
      "✅ 3b5b0747260d5a8240b3211d8952ebf508da49fda1ca6847b5f35de13a6e69908bc5087ea5c5b0a0240ed85ab3b961f1c427ebdf378d19e38b1dc977eac6d367: 380 frames, 19 unique phonemes\n",
      "✅ 870c5afad574bcf1b2c843ee3abc7cc6252bdfa056955a174320e62773211d4d2300d053e1c2b082ee01617c8fdd54162d5bd0334fb000078460c72ef98f4b24: 358 frames, 9 unique phonemes\n",
      "✅ 0787fc53ceffefd5288c674e68bd689b4c7110b3b5501cf2e626a8596089a207b12b147b7213f84687dc12b76099c4f4094393f8bdbc2892d04014effa26965c: 315 frames, 18 unique phonemes\n",
      "✅ 665a9d904c429910fe4622d710f7cf10d833b61e0561810e97cc06c7ca34e9cd7d4dbb8fea26074154344138469da48f8d06b0cecb37da3b8491ccbdfbe65578: 555 frames, 24 unique phonemes\n",
      "✅ 3d1d763d3a5b1bc488d45c4d2a47a4092a68ab7c5366ee6daa61e998a531d52fb7651d371c912ff46e99b7d054b694ba62b6d57e12b74c48fc4b439d59652c65: 375 frames, 18 unique phonemes\n",
      "✅ fbd34121376038a49a293698f15c9faaf23b8e4aafb6a56a2e059f53469ab5528b197db55d4b4d0b7fc0464c95d4fde348d2638ef3bad0d6fcbc6290409f5325: 521 frames, 26 unique phonemes\n",
      "✅ 2694b6761ff8d9e86aad22c1d580761d0271c4bbf87ad0b0f114d6a6cbb5f48e832d2333a4a2b7d38c22a69303ac03b29da525560d4ec6adfc217f9acc3388d1: 505 frames, 22 unique phonemes\n",
      "✅ 35f94333c56b1cdba877e6ee49a417871d9dc1e18a07e3d5e847364df38490e097384cd3ab064e3fc6433603f3812d11fb775a47b8775f96c4d51c54262f0230: 651 frames, 21 unique phonemes\n",
      "✅ ea8a8b7b474d3a60c559dcbd59757bd381c6b5fd75faa591567b1532f6e5722d2ad45a0b641e8cfbac14cd44f7a782d19cad83b50604d2e289d03f24f22195e7: 418 frames, 21 unique phonemes\n",
      "✅ a41b27e28dce11e0499342e7b8e7a31c39088cf6c0ef6e19635e74e6f8f30b801fbd68ed9d979b9736cda8dfbac9710bed52fcc172f0c4f0a4f1a4efb267ffea: 627 frames, 17 unique phonemes\n",
      "✅ 150a79d0f5b3a30353c34fd375f9878c63e516740d9575653ad0e5a774c38fd149f146981f67ea9f036faa0752b492c7a16e5f2f0c64b2df9f78886291dd04d9: 821 frames, 21 unique phonemes\n",
      "\n",
      "Summary:\n",
      "Feature dimensions: {(821, 39), (418, 39), (310, 39), (651, 39), (627, 39), (697, 39), (358, 39), (380, 39), (521, 39), (637, 39), (274, 39), (505, 39), (375, 39), (989, 39), (421, 39), (476, 39), (346, 39), (478, 39), (315, 39), (555, 39)}\n",
      "Total unique phonemes found: 41\n",
      "Phonemes: ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OOV', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'SIL', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH']\n",
      "✅ 8b6f2401d6c5d31d3afa804c37559dce47696cb31735bdd213a3c6567b44c38bdd14b303110a950c71c4cd33d75da0ca43aca8efdb9dedd44ee848e6aa7f8ea6: 310 frames, 13 unique phonemes\n",
      "✅ d6c3894252d0c62099fffaefb680eee43f84cd181a88ec4e219daf2da8e3b4becea0db68f946a9592434d01efe5a2a22890f86ae6fe2728a739dd718ab0dd9a1: 989 frames, 16 unique phonemes\n",
      "✅ a721196a35faa57cae99a3cd0260647d5b64beef00f6d83a2ce38d5c2f8b987faca1043b04e1e3671f43a93a396a8503fdaf5eb9808a960f63524b4ad1088bdc: 274 frames, 12 unique phonemes\n",
      "✅ 39bd19fcce3ff45adf9cf8e6168117f0b0cdba49df6ad802ea0cf80925aba17b193d9dd5627ce676c0c55e05e868c7aac57edb9b788df55db3686680dc96237c: 637 frames, 14 unique phonemes\n",
      "✅ e57df6a9e6756821673bc44742901c456aae90ac7b3e0e6eb94e0611eefa43db9057e14dc960c7ec3a6020b573c9d3ff93be5cb023a912abe9a325b55601a12d: 421 frames, 21 unique phonemes\n",
      "✅ 2f6f2a60f942887092bb3c155d90bdee52ed4927b448f7970a68f3ae87d3206d1ebad14142adc249c198fa2658900263596ff992abe648d0dd8c613178b7bb37: 478 frames, 17 unique phonemes\n",
      "✅ 7b3dd6aa7e1e677c4fc34a7f3723ff6ccc9acb4209b094acd0cfacbc4f85b3e2052f4f9b61cc35909a097d2a0b5a62df1a55861dc0899610645dcaf27e66610e: 476 frames, 18 unique phonemes\n",
      "✅ 3b5b0747260d5a8240b3211d8952ebf508da49fda1ca6847b5f35de13a6e69908bc5087ea5c5b0a0240ed85ab3b961f1c427ebdf378d19e38b1dc977eac6d367: 380 frames, 19 unique phonemes\n",
      "✅ 870c5afad574bcf1b2c843ee3abc7cc6252bdfa056955a174320e62773211d4d2300d053e1c2b082ee01617c8fdd54162d5bd0334fb000078460c72ef98f4b24: 358 frames, 9 unique phonemes\n",
      "✅ 0787fc53ceffefd5288c674e68bd689b4c7110b3b5501cf2e626a8596089a207b12b147b7213f84687dc12b76099c4f4094393f8bdbc2892d04014effa26965c: 315 frames, 18 unique phonemes\n",
      "✅ 665a9d904c429910fe4622d710f7cf10d833b61e0561810e97cc06c7ca34e9cd7d4dbb8fea26074154344138469da48f8d06b0cecb37da3b8491ccbdfbe65578: 555 frames, 24 unique phonemes\n",
      "✅ 3d1d763d3a5b1bc488d45c4d2a47a4092a68ab7c5366ee6daa61e998a531d52fb7651d371c912ff46e99b7d054b694ba62b6d57e12b74c48fc4b439d59652c65: 375 frames, 18 unique phonemes\n",
      "✅ fbd34121376038a49a293698f15c9faaf23b8e4aafb6a56a2e059f53469ab5528b197db55d4b4d0b7fc0464c95d4fde348d2638ef3bad0d6fcbc6290409f5325: 521 frames, 26 unique phonemes\n",
      "✅ 2694b6761ff8d9e86aad22c1d580761d0271c4bbf87ad0b0f114d6a6cbb5f48e832d2333a4a2b7d38c22a69303ac03b29da525560d4ec6adfc217f9acc3388d1: 505 frames, 22 unique phonemes\n",
      "✅ 35f94333c56b1cdba877e6ee49a417871d9dc1e18a07e3d5e847364df38490e097384cd3ab064e3fc6433603f3812d11fb775a47b8775f96c4d51c54262f0230: 651 frames, 21 unique phonemes\n",
      "✅ ea8a8b7b474d3a60c559dcbd59757bd381c6b5fd75faa591567b1532f6e5722d2ad45a0b641e8cfbac14cd44f7a782d19cad83b50604d2e289d03f24f22195e7: 418 frames, 21 unique phonemes\n",
      "✅ a41b27e28dce11e0499342e7b8e7a31c39088cf6c0ef6e19635e74e6f8f30b801fbd68ed9d979b9736cda8dfbac9710bed52fcc172f0c4f0a4f1a4efb267ffea: 627 frames, 17 unique phonemes\n",
      "✅ 150a79d0f5b3a30353c34fd375f9878c63e516740d9575653ad0e5a774c38fd149f146981f67ea9f036faa0752b492c7a16e5f2f0c64b2df9f78886291dd04d9: 821 frames, 21 unique phonemes\n",
      "\n",
      "Summary:\n",
      "Feature dimensions: {(821, 39), (418, 39), (310, 39), (651, 39), (627, 39), (697, 39), (358, 39), (380, 39), (521, 39), (637, 39), (274, 39), (505, 39), (375, 39), (989, 39), (421, 39), (476, 39), (346, 39), (478, 39), (315, 39), (555, 39)}\n",
      "Total unique phonemes found: 41\n",
      "Phonemes: ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OOV', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'SIL', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH']\n"
     ]
    }
   ],
   "source": [
    "# Data validation and analysis functions\n",
    "def validate_extracted_features(features_dir, labels_dir, sample_size=10):\n",
    "    \"\"\"Validate extracted features and labels\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VALIDATING EXTRACTED DATA\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    features_dir = Path(features_dir)\n",
    "    labels_dir = Path(labels_dir)\n",
    "    \n",
    "    feature_files = list(features_dir.glob(\"*.npy\"))\n",
    "    label_files = list(labels_dir.glob(\"*.txt\"))\n",
    "    \n",
    "    print(f\"Feature files: {len(feature_files)}\")\n",
    "    print(f\"Label files: {len(label_files)}\")\n",
    "    \n",
    "    # Check matching files\n",
    "    feature_bases = {f.stem for f in feature_files}\n",
    "    label_bases = {f.stem for f in label_files}\n",
    "    \n",
    "    matching = feature_bases & label_bases\n",
    "    missing_labels = feature_bases - label_bases\n",
    "    missing_features = label_bases - feature_bases\n",
    "    \n",
    "    print(f\"Matching pairs: {len(matching)}\")\n",
    "    if missing_labels:\n",
    "        print(f\"Missing labels: {len(missing_labels)}\")\n",
    "    if missing_features:\n",
    "        print(f\"Missing features: {len(missing_features)}\")\n",
    "    \n",
    "    # Sample validation\n",
    "    if matching:\n",
    "        sample_files = list(matching)[:sample_size]\n",
    "        print(f\"\\nValidating {len(sample_files)} sample files...\")\n",
    "        \n",
    "        all_phonemes = set()\n",
    "        feature_shapes = []\n",
    "        \n",
    "        for base in sample_files:\n",
    "            try:\n",
    "                # Load features\n",
    "                features = np.load(features_dir / f\"{base}.npy\")\n",
    "                feature_shapes.append(features.shape)\n",
    "                \n",
    "                # Load labels\n",
    "                with open(labels_dir / f\"{base}.txt\", 'r') as f:\n",
    "                    labels = [line.strip() for line in f.readlines()]\n",
    "                \n",
    "                all_phonemes.update(labels)\n",
    "                \n",
    "                # Check alignment\n",
    "                if features.shape[0] != len(labels):\n",
    "                    print(f\"⚠️ Length mismatch in {base}: features={features.shape[0]}, labels={len(labels)}\")\n",
    "                else:\n",
    "                    print(f\"✅ {base}: {features.shape[0]} frames, {len(set(labels))} unique phonemes\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error validating {base}: {e}\")\n",
    "        \n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"Feature dimensions: {set(feature_shapes)}\")\n",
    "        print(f\"Total unique phonemes found: {len(all_phonemes)}\")\n",
    "        print(f\"Phonemes: {sorted(all_phonemes)}\")\n",
    "        \n",
    "        return {\n",
    "            'total_files': len(matching),\n",
    "            'feature_shapes': feature_shapes,\n",
    "            'phonemes': sorted(all_phonemes),\n",
    "            'missing_labels': len(missing_labels),\n",
    "            'missing_features': len(missing_features)\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Run validation\n",
    "validation_results = validate_extracted_features(\n",
    "    extractor.features_out, \n",
    "    extractor.labels_out, \n",
    "    sample_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4346a",
   "metadata": {},
   "source": [
    "## Remove OOV Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a69ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_oov_data(self, remove_oov_utterances=False, segment_at_oov=True, replace_with_silence=False):\n",
    "    \"\"\"\n",
    "    Clean OOV labels from extracted features and labels\n",
    "    \n",
    "    Args:\n",
    "        remove_oov_utterances: Remove entire utterances that contain OOV\n",
    "        segment_at_oov: Split sequences at OOV boundaries (recommended)\n",
    "        replace_with_silence: Replace OOV with SIL instead of segmenting\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CLEANING OOV DATA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    feature_files = list(self.features_out.glob(\"*.npy\"))\n",
    "    total_files = len(feature_files)\n",
    "    total_segments_created = 0\n",
    "    total_utterances_removed = 0\n",
    "    total_oov_frames = 0\n",
    "    \n",
    "    # Create clean output directories\n",
    "    clean_features_dir = self.base_dir / \"features_clean\"\n",
    "    clean_labels_dir = self.base_dir / \"labels_clean\"\n",
    "    clean_features_dir.mkdir(exist_ok=True)\n",
    "    clean_labels_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    oov_stats = {}\n",
    "    \n",
    "    for feature_file in tqdm(feature_files, desc=\"Processing files\"):\n",
    "        base_name = feature_file.stem\n",
    "        label_file = self.labels_out / f\"{base_name}.txt\"\n",
    "        \n",
    "        if not label_file.exists():\n",
    "            continue\n",
    "            \n",
    "        # Load features and labels\n",
    "        features = np.load(feature_file)\n",
    "        with open(label_file, 'r') as f:\n",
    "            labels = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        # Check for OOV\n",
    "        oov_indices = [i for i, label in enumerate(labels) if label == 'OOV']\n",
    "        \n",
    "        if not oov_indices:\n",
    "            # No OOV, copy as is\n",
    "            np.save(clean_features_dir / f\"{base_name}.npy\", features)\n",
    "            with open(clean_labels_dir / f\"{base_name}.txt\", 'w') as f:\n",
    "                f.write('\\n'.join(labels))\n",
    "            continue\n",
    "        \n",
    "        total_oov_frames += len(oov_indices)\n",
    "        oov_stats[base_name] = len(oov_indices)\n",
    "        \n",
    "        if remove_oov_utterances:\n",
    "            # Skip entire utterance if it contains OOV\n",
    "            total_utterances_removed += 1\n",
    "            continue\n",
    "        \n",
    "        if replace_with_silence:\n",
    "            # Replace OOV with SIL\n",
    "            clean_labels = [label if label != 'OOV' else 'SIL' for label in labels]\n",
    "            np.save(clean_features_dir / f\"{base_name}.npy\", features)\n",
    "            with open(clean_labels_dir / f\"{base_name}.txt\", 'w') as f:\n",
    "                f.write('\\n'.join(clean_labels))\n",
    "            continue\n",
    "        \n",
    "        if segment_at_oov:\n",
    "            # Segment at OOV boundaries\n",
    "            segments = self._create_segments_from_oov(features, labels, oov_indices)\n",
    "            \n",
    "            for seg_idx, (seg_features, seg_labels) in enumerate(segments):\n",
    "                if len(seg_features) < 10:  # Skip very short segments\n",
    "                    continue\n",
    "                \n",
    "                segment_name = f\"{base_name}_seg{seg_idx:02d}\"\n",
    "                np.save(clean_features_dir / f\"{segment_name}.npy\", seg_features)\n",
    "                with open(clean_labels_dir / f\"{segment_name}.txt\", 'w') as f:\n",
    "                    f.write('\\n'.join(seg_labels))\n",
    "                total_segments_created += 1\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\n📊 OOV Cleaning Results:\")\n",
    "    print(f\"Total files processed: {total_files}\")\n",
    "    print(f\"Files with OOV: {len(oov_stats)}\")\n",
    "    print(f\"Total OOV frames removed: {total_oov_frames}\")\n",
    "    \n",
    "    if remove_oov_utterances:\n",
    "        print(f\"Utterances removed: {total_utterances_removed}\")\n",
    "    elif segment_at_oov:\n",
    "        print(f\"Segments created: {total_segments_created}\")\n",
    "    \n",
    "    return oov_stats\n",
    "\n",
    "def _create_segments_from_oov(self, features, labels, oov_indices):\n",
    "    \"\"\"Create segments by splitting at OOV boundaries\"\"\"\n",
    "    segments = []\n",
    "    \n",
    "    # Add boundaries at start, OOV positions, and end\n",
    "    boundaries = [0] + oov_indices + [len(labels)]\n",
    "    boundaries = sorted(set(boundaries))  # Remove duplicates and sort\n",
    "    \n",
    "    for i in range(len(boundaries) - 1):\n",
    "        start = boundaries[i]\n",
    "        end = boundaries[i + 1]\n",
    "        \n",
    "        # Skip if this segment would start with OOV\n",
    "        if start in oov_indices:\n",
    "            # Find next non-OOV position\n",
    "            while start < end and start in oov_indices:\n",
    "                start += 1\n",
    "        \n",
    "        # Skip if this segment would end with OOV  \n",
    "        if end - 1 in oov_indices:\n",
    "            # Find last non-OOV position\n",
    "            while end > start and (end - 1) in oov_indices:\n",
    "                end -= 1\n",
    "        \n",
    "        if start < end and end - start >= 5:  # Minimum segment length\n",
    "            seg_features = features[start:end]\n",
    "            seg_labels = labels[start:end]\n",
    "            \n",
    "            # Verify no OOV in this segment\n",
    "            if 'OOV' not in seg_labels:\n",
    "                segments.append((seg_features, seg_labels))\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# Add method to FeatureExtractor class\n",
    "FeatureExtractor.clean_oov_data = clean_oov_data\n",
    "FeatureExtractor._create_segments_from_oov = _create_segments_from_oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c2cad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLEANING OOV DATA\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 26482/26482 [05:12<00:00, 84.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 OOV Cleaning Results:\n",
      "Total files processed: 26482\n",
      "Files with OOV: 6136\n",
      "Total OOV frames removed: 298734\n",
      "Segments created: 13079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov_stats = extractor.clean_oov_data(segment_at_oov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3f9bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VALIDATING CLEANED DATA\n",
      "============================================================\n",
      "Clean feature files: 33425\n",
      "Clean label files: 33425\n",
      "\n",
      "Checking 20 sample files for OOV...\n",
      "✅ 0001de01fdda751c9232125a5abf13b96a40786d90edae74724c441d867fea3238a4cd28be62255ab3881695c93a8b21a5818c0fa400642493da246be69df417: 334 frames, 18 unique phonemes\n",
      "✅ 000678f13f95dba9bd927bd4e955233c4168496654e5629981f21bd3bdeef10af51d761b55ca11657f4844c836d61ef8502ee18b7edeb9520e216b3e5fdad561: 435 frames, 26 unique phonemes\n",
      "✅ 00088b44ab0466aa98e4515a7d44b50f8890d2bbbe457899ba549456c8273afb6da8c557c4842f19cb52cd4c1c83cf628994dcc8f4f1c7e9b4d0930d0ee13805_seg00: 155 frames, 9 unique phonemes\n",
      "✅ 00088b44ab0466aa98e4515a7d44b50f8890d2bbbe457899ba549456c8273afb6da8c557c4842f19cb52cd4c1c83cf628994dcc8f4f1c7e9b4d0930d0ee13805_seg01: 12 frames, 1 unique phonemes\n",
      "✅ 00088b44ab0466aa98e4515a7d44b50f8890d2bbbe457899ba549456c8273afb6da8c557c4842f19cb52cd4c1c83cf628994dcc8f4f1c7e9b4d0930d0ee13805_seg02: 229 frames, 15 unique phonemes\n",
      "✅ 000948bbca46377ba9cf2d3be56a95926e7eb35bc17317dea7e5a7fdae57556a005fa88f1f28c4a3ac3c8ff2cd21a9a5cf96825d0a6059c0b5631f6afafe6f00: 545 frames, 21 unique phonemes\n",
      "✅ 000a24b376ea168f37fffb466429b9aef246bd14b99c12b85c7f7f3d6b594d223fd876243ff441e880c6f38713a992dc6994c3844cf3fb17e8589485e10b8144: 435 frames, 12 unique phonemes\n",
      "✅ 000b1fc02cf8928b9cc0c23168a4ca606861765e087f00e32f2aa034ef64ebb9ffd31ab5f02b34f66eb1a4249096f3732cf8249599905c8dc4ad91ea6e57864f_seg00: 192 frames, 11 unique phonemes\n",
      "✅ 000b1fc02cf8928b9cc0c23168a4ca606861765e087f00e32f2aa034ef64ebb9ffd31ab5f02b34f66eb1a4249096f3732cf8249599905c8dc4ad91ea6e57864f_seg01: 247 frames, 14 unique phonemes\n",
      "✅ 000b4a64de15cbe995de54ffd8010a627fdccc809c9a3ed999c85c2811ab6d22068030e13c9ae4427fcc496f212f5c9ae7ac3229a30a0b72a0bcdf49bedb4e40: 428 frames, 12 unique phonemes\n",
      "✅ 000bbe80d7bae0eedc4b85b294c06ae96bb7c2b4efe610a846484c73ed8e98f8e1b5deb93f1ed6193e80f07b8e3fb9ee2e906a02b359b1390e401d93d272047d: 363 frames, 13 unique phonemes\n",
      "✅ 000c5bff9b4c95b7aca99e011e7296141b844a40c62daf1811d80ba567bd88a4c077fdc6535e096e5922b04a64ecd514b96738d877dcc1c6755eae3c19c424fa: 341 frames, 16 unique phonemes\n",
      "✅ 0013fd2823a6475bbd10b3ce8c7b658b926df2a116e8ac8915a92769e61e299064199503d237b50b9e45cc6acd62b642fa2774fdbaaf1952500b3442b63eb3d2: 975 frames, 18 unique phonemes\n",
      "✅ 00159b0cd6b3da80993677b57f13942b9926556f7ceff138344c20b38e310313b26be0c64807a62349c7425544c4b122457bda5b087da88cfec7fc4427807264_seg00: 127 frames, 1 unique phonemes\n",
      "✅ 00159b0cd6b3da80993677b57f13942b9926556f7ceff138344c20b38e310313b26be0c64807a62349c7425544c4b122457bda5b087da88cfec7fc4427807264_seg01: 375 frames, 21 unique phonemes\n",
      "✅ 0015b3d96ac0f0e19ed72df13edf9672b69155497435e023099eef3f2efa3a81e8118010b698e3e2ea22e9d7e9ad5723cee1110e23b46f599561924c75e760c3: 339 frames, 18 unique phonemes\n",
      "✅ 00161b47754738e3e648b1850d8a9293f48d55a4f7ca44b16cbf8e13ffaa2aa3dab01b91ccea32be3a331499ec7ecfc7330bac73950097842788540ae5587626: 603 frames, 19 unique phonemes\n",
      "✅ 001754ef38bc7607b6b450feb70c57458f509d6b25a9ad35eaf23f2611e1cceb03b2952a79b7c3cf72c907fbc5ed991126d4b6297cc7a8406f8fa7c421543975_seg00: 328 frames, 19 unique phonemes\n",
      "✅ 001754ef38bc7607b6b450feb70c57458f509d6b25a9ad35eaf23f2611e1cceb03b2952a79b7c3cf72c907fbc5ed991126d4b6297cc7a8406f8fa7c421543975_seg01: 127 frames, 9 unique phonemes\n",
      "✅ 0017cb9ae0e95f6708f06fcec9f9820b7672d2d5ffd7102b383f934695807b2a2e6aabc44408c0be39f2f63f115ce9810a2351aa0ed2bcb284b72def6ea5d7f4_seg00: 115 frames, 6 unique phonemes\n",
      "\n",
      "📊 Validation Results:\n",
      "Total frames checked: 6705\n",
      "Total OOV found: 0\n",
      "OOV percentage: 0.0000%\n",
      "Unique phonemes in sample: 38\n",
      "Phonemes: ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'P', 'R', 'S', 'SH', 'SIL', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z']\n",
      "\n",
      "📈 File Distribution:\n",
      "Original files (no OOV): 20346\n",
      "Segment files (from OOV split): 13079\n",
      "Total clean files: 33425\n"
     ]
    }
   ],
   "source": [
    "# Validate cleaned data\n",
    "def validate_cleaned_data():\n",
    "    \"\"\"Validate the cleaned features and labels\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VALIDATING CLEANED DATA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    clean_features_dir = extractor.base_dir / \"features_clean\"\n",
    "    clean_labels_dir = extractor.base_dir / \"labels_clean\"\n",
    "    \n",
    "    # Count files\n",
    "    clean_feature_files = list(clean_features_dir.glob(\"*.npy\"))\n",
    "    clean_label_files = list(clean_labels_dir.glob(\"*.txt\"))\n",
    "    \n",
    "    print(f\"Clean feature files: {len(clean_feature_files)}\")\n",
    "    print(f\"Clean label files: {len(clean_label_files)}\")\n",
    "    \n",
    "    # Sample some files to check for OOV\n",
    "    sample_files = clean_label_files[:20]\n",
    "    total_oov_found = 0\n",
    "    total_frames = 0\n",
    "    all_phonemes = set()\n",
    "    \n",
    "    print(f\"\\nChecking {len(sample_files)} sample files for OOV...\")\n",
    "    \n",
    "    for label_file in sample_files:\n",
    "        base_name = label_file.stem\n",
    "        feature_file = clean_features_dir / f\"{base_name}.npy\"\n",
    "        \n",
    "        if feature_file.exists():\n",
    "            # Load labels and check for OOV\n",
    "            with open(label_file, 'r') as f:\n",
    "                labels = [line.strip() for line in f.readlines()]\n",
    "            \n",
    "            # Load features\n",
    "            features = np.load(feature_file)\n",
    "            \n",
    "            oov_count = labels.count('OOV')\n",
    "            total_oov_found += oov_count\n",
    "            total_frames += len(labels)\n",
    "            all_phonemes.update(labels)\n",
    "            \n",
    "            if oov_count > 0:\n",
    "                print(f\"⚠️ Found {oov_count} OOV in {base_name}\")\n",
    "            else:\n",
    "                print(f\"✅ {base_name}: {len(labels)} frames, {len(set(labels))} unique phonemes\")\n",
    "    \n",
    "    print(f\"\\n📊 Validation Results:\")\n",
    "    print(f\"Total frames checked: {total_frames}\")\n",
    "    print(f\"Total OOV found: {total_oov_found}\")\n",
    "    print(f\"OOV percentage: {(total_oov_found/total_frames)*100:.4f}%\")\n",
    "    print(f\"Unique phonemes in sample: {len(all_phonemes)}\")\n",
    "    print(f\"Phonemes: {sorted(all_phonemes)}\")\n",
    "    \n",
    "    # Check for segment files\n",
    "    segment_files = [f for f in clean_feature_files if '_seg' in f.name]\n",
    "    original_files = [f for f in clean_feature_files if '_seg' not in f.name]\n",
    "    \n",
    "    print(f\"\\n📈 File Distribution:\")\n",
    "    print(f\"Original files (no OOV): {len(original_files)}\")\n",
    "    print(f\"Segment files (from OOV split): {len(segment_files)}\")\n",
    "    print(f\"Total clean files: {len(clean_feature_files)}\")\n",
    "    \n",
    "    return {\n",
    "        'total_files': len(clean_feature_files),\n",
    "        'original_files': len(original_files),\n",
    "        'segment_files': len(segment_files),\n",
    "        'oov_found': total_oov_found,\n",
    "        'phonemes': sorted(all_phonemes)\n",
    "    }\n",
    "\n",
    "# Run validation\n",
    "validation_results = validate_cleaned_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
