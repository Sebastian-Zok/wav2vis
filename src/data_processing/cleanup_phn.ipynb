{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9c3c38a1-375d-4520-a67a-a9ada61dbae9",
      "metadata": {},
      "source": [
        "# Prepare PHN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f386cbf4",
      "metadata": {},
      "source": [
        "### Analyse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cc26a838-5908-43d0-9074-ccd39f296c51",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Label Verteilung ---\n",
            "SIL: 110639 Frames (12.37%)\n",
            "ah: 73024 Frames (8.17%)\n",
            "t: 59095 Frames (6.61%)\n",
            "n: 51704 Frames (5.78%)\n",
            "ih: 50133 Frames (5.61%)\n",
            "d: 35973 Frames (4.02%)\n",
            "s: 35545 Frames (3.97%)\n",
            "r: 30188 Frames (3.38%)\n",
            "l: 29738 Frames (3.33%)\n",
            "iy: 28853 Frames (3.23%)\n",
            "dh: 26305 Frames (2.94%)\n",
            "m: 23660 Frames (2.65%)\n",
            "k: 22102 Frames (2.47%)\n",
            "ae: 21505 Frames (2.40%)\n",
            "eh: 21444 Frames (2.40%)\n",
            "z: 21277 Frames (2.38%)\n",
            "w: 20140 Frames (2.25%)\n",
            "er: 19586 Frames (2.19%)\n",
            "ay: 16468 Frames (1.84%)\n",
            "hh: 16232 Frames (1.82%)\n",
            "b: 15881 Frames (1.78%)\n",
            "uw: 15026 Frames (1.68%)\n",
            "p: 14862 Frames (1.66%)\n",
            "v: 13115 Frames (1.47%)\n",
            "f: 12782 Frames (1.43%)\n",
            "ey: 12553 Frames (1.40%)\n",
            "ao: 12197 Frames (1.36%)\n",
            "aa: 10806 Frames (1.21%)\n",
            "ow: 10668 Frames (1.19%)\n",
            "ng: 10474 Frames (1.17%)\n",
            "y: 7617 Frames (0.85%)\n",
            "g: 7293 Frames (0.82%)\n",
            "oov: 7018 Frames (0.78%)\n",
            "aw: 5966 Frames (0.67%)\n",
            "th: 5878 Frames (0.66%)\n",
            "sh: 4853 Frames (0.54%)\n",
            "uh: 4306 Frames (0.48%)\n",
            "jh: 3558 Frames (0.40%)\n",
            "ch: 3118 Frames (0.35%)\n",
            "oy: 2268 Frames (0.25%)\n",
            "zh: 377 Frames (0.04%)\n",
            "\n",
            "Gesamtanzahl Frames: 894227\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# Verzeichnisse\n",
        "labels_dir = \"data/en/phn\"\n",
        "\n",
        "# Initialisierung\n",
        "label_counter = Counter()\n",
        "total_frames = 0\n",
        "\n",
        "# Alle Label-Dateien durchgehen\n",
        "label_files = [f for f in os.listdir(labels_dir) if f.endswith(\".phn\")]\n",
        "\n",
        "for file in label_files:\n",
        "    with open(os.path.join(labels_dir, file), \"r\") as f:\n",
        "        lines = f.read().splitlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) == 3:\n",
        "                label = parts[2]\n",
        "                label_counter.update([label])\n",
        "                total_frames += 1\n",
        "\n",
        "# Ausgabe\n",
        "print(\"--- Label Verteilung ---\")\n",
        "for label, count in label_counter.most_common():\n",
        "    percent = count / total_frames * 100\n",
        "    print(f\"{label}: {count} Frames ({percent:.2f}%)\")\n",
        "\n",
        "print(f\"\\nGesamtanzahl Frames: {total_frames}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3393ebe2-95e2-4059-8f90-bfda8754b29d",
      "metadata": {},
      "source": [
        "# Clean up \n",
        "Remove Suffix and cobine SILs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "093df54b-4b2f-4385-9255-f956e72e8309",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alle .phn-Dateien wurden bereinigt (Suffixe entfernt, SIL vereinheitlicht).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Ordner mit PHN-Dateien\n",
        "phn_dir = Path(\"data/en/phn\")\n",
        "\n",
        "# Definition der Silence-Bezeichner (die zu \"SIL\" normalisiert werden sollen)\n",
        "sil_labels = {\"sil\", \"SIL\", \"silence\", \"SILENCE\"}\n",
        "\n",
        "# Alle .phn-Dateien durchgehen\n",
        "for phn_file in phn_dir.glob(\"*.phn\"):\n",
        "    new_lines = []\n",
        "\n",
        "    with open(phn_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.read().splitlines()\n",
        "\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) != 3:\n",
        "            continue  # Ung√ºltige Zeile √ºberspringen\n",
        "\n",
        "        start, end, label = parts\n",
        "\n",
        "        # Silence vereinheitlichen\n",
        "        base_label = label.split(\"_\")[0].lower()\n",
        "        if base_label in sil_labels:\n",
        "            cleaned_label = \"SIL\"\n",
        "        else:\n",
        "            # Nur Phonem ohne Suffix behalten\n",
        "            cleaned_label = label.split(\"_\")[0]\n",
        "\n",
        "        new_lines.append(f\"{start} {end} {cleaned_label}\")\n",
        "\n",
        "    # Datei √ºberschreiben\n",
        "    with open(phn_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(new_lines))\n",
        "\n",
        "print(\"Alle .phn-Dateien wurden bereinigt (Suffixe entfernt, SIL vereinheitlicht).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b8d5121-223d-4df6-a064-8581af51b087",
      "metadata": {},
      "source": [
        "### Remove OOV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9d3ab85c-4353-47ac-b51d-a7d6abd63d8a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OOV-Entfernung: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26482/26482 [05:37<00:00, 78.43dateien/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- OOV-Bereinigung abgeschlossen ---\n",
            "üì¶ Verarbeitete Dateien: 26482\n",
            "üßπ Entfernte OOV-Frames: 293337\n",
            "‚úÖ Verbleibende Frames: 13943888\n",
            "üìÅ Gespeichert in: data\\en\\features_clean und data\\en\\labels_clean\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Eingabe- und Ausgabeordner\n",
        "base_dir = Path(\"data/en\")\n",
        "features_in = base_dir / \"features\"\n",
        "labels_in = base_dir / \"labels\"\n",
        "features_out = base_dir / \"features_clean\"\n",
        "labels_out = base_dir / \"labels_clean\"\n",
        "features_out.mkdir(exist_ok=True)\n",
        "labels_out.mkdir(exist_ok=True)\n",
        "\n",
        "# Alle Dateien iterieren\n",
        "files = list(features_in.glob(\"*.npy\"))\n",
        "\n",
        "removed_frames = 0\n",
        "total_frames = 0\n",
        "kept_files = 0\n",
        "\n",
        "for feat_path in tqdm(files, desc=\"OOV-Entfernung\", unit=\"dateien\"):\n",
        "    base = feat_path.stem\n",
        "    label_path = labels_in / f\"{base}.txt\"\n",
        "\n",
        "    if not label_path.exists():\n",
        "        continue\n",
        "\n",
        "    # Lade Features und Labels\n",
        "    features = np.load(feat_path)\n",
        "    with open(label_path) as f:\n",
        "        labels = [line.strip() for line in f]\n",
        "\n",
        "    assert len(features) == len(labels), f\"Mismatch in {base}\"\n",
        "\n",
        "    # Filtere alles au√üer OOV\n",
        "    mask = [l != \"oov\" for l in labels]\n",
        "    features_clean = features[mask]\n",
        "    labels_clean = [l for l in labels if l != \"oov\"]\n",
        "\n",
        "    removed = len(labels) - len(labels_clean)\n",
        "    removed_frames += removed\n",
        "    total_frames += len(labels)\n",
        "    kept_files += 1\n",
        "\n",
        "    # Speichern\n",
        "    np.save(features_out / f\"{base}.npy\", features_clean)\n",
        "    with open(labels_out / f\"{base}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(labels_clean))\n",
        "\n",
        "print(f\"\\n--- OOV-Bereinigung abgeschlossen ---\")\n",
        "print(f\"üì¶ Verarbeitete Dateien: {kept_files}\")\n",
        "print(f\"üßπ Entfernte OOV-Frames: {removed_frames}\")\n",
        "print(f\"‚úÖ Verbleibende Frames: {total_frames - removed_frames}\")\n",
        "print(f\"üìÅ Gespeichert in: {features_out} und {labels_out}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
